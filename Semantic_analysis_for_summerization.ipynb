{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "import numbers\n",
    "import nltk\n",
    "import csv, random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fd = open(\"C:\\Users\\MY PC\\Desktop\\semantic-similarity-between-multilingual-data-corpus\\semantic-similarity-between-multilingual-data-corpus\\Data\\totc_eng.txt\")\n",
    "#corpus = fd.read()\n",
    "corpus = \" In the production of SMC (Sheet Moulding Compound), the maturing of the semi-finished product (resin+glass fibre) is of decisive importance. The associated thickening of the material determines the viscosity and thus the quality of the end product. Possible defects due to short maturing and soft semi-finished products are lack of fibre transport, while too long maturing and hard semi-finished products result in incompletely filled components. By adjusting the press parameters such as closing force, closing speed, mould temperature etc., the fluctuations in thickening can normally be compensated. By measuring the flowability/viscosity of the material or by measuring additional parameters during the manufacturing process, the ideal process window for the production of SMC is to be controlled even better.\"\n",
    "cust_sent_tokenize = PunktSentenceTokenizer(corpus)\n",
    "corpus_arr = cust_sent_tokenize.tokenize(corpus)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    "\n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    "\n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    "\n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def tagged_to_synset_en(word):\n",
    "    try:\n",
    "        lemmas = wordnet.lemmas(word, lang=\"eng\")\n",
    "        hypernyms = lemmas[0].synset().hypernyms()\n",
    "        return hypernyms\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def sentence_similarity_en(sentence, mth):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    sentence2 = []\n",
    "    sentence1 = word_tokenize(sentence)\n",
    "    # random.shuffle(corpus_arr)\n",
    "    for w in corpus_arr[:20]:\n",
    "        sentence2 = sentence2 + word_tokenize(w)\n",
    "\n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset_en(tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset_en(tagged_word) for tagged_word in sentence2]\n",
    "\n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss[0] for ss in synsets1 if ss]\n",
    "    synsets2 = [ss[0] for ss in synsets2 if ss]\n",
    "\n",
    "    score, count = 0.0, 0\n",
    "\n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        if mth == 'path':\n",
    "            scores = [synset.path_similarity(ss) for ss in synsets2]\n",
    "        elif mth == 'wu':\n",
    "            scores = [synset.wup_similarity(ss) for ss in synsets2]\n",
    "\n",
    "        numscore = [x for x in scores if isinstance(x, numbers.Number)]\n",
    "        if len(numscore) != 0:\n",
    "            best_score = sum(numscore)/len(numscore)\n",
    "            # Check that the similarity could have been computed\n",
    "            if best_score is not None:\n",
    "                score += best_score\n",
    "\n",
    "        else:\n",
    "            score += 0\n",
    "        count += 1\n",
    "\n",
    "    # Average the values\n",
    "    if count == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        score /= count\n",
    "        return score\n",
    "\n",
    "# convert percentage into scores\n",
    "def score_generator(score):\n",
    "    if score >= 0 and score <= 0.2:\n",
    "        return 0\n",
    "    elif score > 0.2 and score <= 0.4:\n",
    "        return 1\n",
    "    elif score > 0.4 and score <= 0.6:\n",
    "        return 2\n",
    "    elif score > 0.6 and score <= 0.8:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "# write into CSV\n",
    "def model_gen(sentences):\n",
    "    with open('res.csv','w',encoding='utf8') as csvfile:\n",
    "        fieldnames = ['Sentences', 'Score']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for sentence in sentences:\n",
    "            path_sem_sim = sentence_similarity_en(sentence, 'wu')\n",
    "            writer.writerow({'Sentences': sentence, 'Score': path_sem_sim})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files created!\n"
     ]
    }
   ],
   "source": [
    "model_gen(corpus_arr)\n",
    "\n",
    "print(\"CSV files created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
